{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "be4nBharassa"
   },
   "source": [
    "The first step in our process was to scrape the news articles.  We decided to use News API, because it covered a large range of sources and was free to use for our purposes.  One drawback was that it only allowed us to scrape articles in the past 30 days.  \n",
    "\n",
    "We used the Media Bias chart created by Ad Fontes Media to determine which sources to pull from.  Our initial scrape we decided to use 1 conservative and 1 liberal source that were described as hyper partisan by the chart and 2 sources that were described as skewed.  We then scraped 3 sources that were described as neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBZB8O_abuYb"
   },
   "source": [
    "News API requires you to use a keyword (denoted by 'q = ') to scrape articles, it will scrape the articles that have that keyword located within them.  For our initial scrape we decided to use broad terms to see how many articles we can get.  Further scrapes we may need to be more precise about the terms we use, but need to consider how that may bias our results.\n",
    "\n",
    "The pageSize attribute is how many articles from the batch that will be included in the list object that is retrieved.  For our initial scrape we decided to use 100.  In future scrapes we may decide to use a higher number, or lower.\n",
    "\n",
    "Sorting by popularity will allow us to retrieve the retrieve the most viewed articles of the bunch.  We may also need to consider how this could potentially bias our results.\n",
    "\n",
    "This process was repeated almost identically for the Conservative, Liberal, and Neutral news sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPK106ZH832q"
   },
   "source": [
    "# Conservative Sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WVE-maUmXq2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url_fox1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=fox-news&'\n",
    "       'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_fox1 = requests.get(url_fox1)\n",
    "\n",
    "#print(response_fox1.content)\n",
    "\n",
    "url_fox2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=fox-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_fox2 = requests.get(url_fox2)\n",
    "\n",
    "#response_fox2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQOA-qUG6Zn2"
   },
   "outputs": [],
   "source": [
    "url_nreview1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=national-review&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_nreview1 = requests.get(url_nreview1)\n",
    "\n",
    "#print(response_nreview1.content)\n",
    "\n",
    "url_nreview2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=national-review&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_nreview2 = requests.get(url_nreview2)\n",
    "\n",
    "#print(response_nreview2.content)\n",
    "\n",
    "url_nreview3 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=what&'\n",
    "       'sources=national-review&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_nreview3 = requests.get(url_nreview3)\n",
    "\n",
    "#response_nreview3.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGgmVNLT7Pk2"
   },
   "outputs": [],
   "source": [
    "url_bart1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=breitbart-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_bart1 = requests.get(url_bart1)\n",
    "\n",
    "#print(response_bart1.content)\n",
    "\n",
    "url_bart2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=breitbart-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_bart2 = requests.get(url_bart2)\n",
    "\n",
    "#response_bart2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8TuNe--_8yea"
   },
   "source": [
    "# Liberal Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qV-NlflP8xAt"
   },
   "outputs": [],
   "source": [
    "url_vice1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=vice-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_vice1 = requests.get(url_vice1)\n",
    "\n",
    "#print(response_vice1.content)\n",
    "\n",
    "url_vice2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=what&'\n",
    "       'sources=vice-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_vice2 = requests.get(url_vice2)\n",
    "\n",
    "#print(response_vice2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SobKN6njAU01"
   },
   "outputs": [],
   "source": [
    "url_msnbc1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=msnbc&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_msnbc1 = requests.get(url_msnbc1)\n",
    "\n",
    "#print(response_msnbc1.content)\n",
    "\n",
    "url_msnbc2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=what&'\n",
    "       'sources=msnbc&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_msnbc2 = requests.get(url_msnbc2)\n",
    "\n",
    "#print(response_msnbc2.content)\n",
    "\n",
    "url_msnbc3 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=msnbc&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_msnbc3 = requests.get(url_msnbc3)\n",
    "\n",
    "#print(response_msnbc3.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-kC7Wi1BcZO"
   },
   "outputs": [],
   "source": [
    "url_buzz1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=buzzfeed&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_buzz1 = requests.get(url_buzz1)\n",
    "\n",
    "#print(response_buzz1.content)\n",
    "\n",
    "url_buzz2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=buzzfeed&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_buzz2 = requests.get(url_buzz2)\n",
    "\n",
    "#print(response_buzz2.content)\n",
    "\n",
    "url_buzz3 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=news&'\n",
    "       'sources=buzzfeed&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_buzz3 = requests.get(url_buzz3)\n",
    "\n",
    "#print(response_buzz3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8l1twfXjCGPb"
   },
   "source": [
    "# Neutral Sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6A2Yz537CFSE"
   },
   "outputs": [],
   "source": [
    "url_cbs1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=cbs-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_cbs1 = requests.get(url_cbs1)\n",
    "\n",
    "#print(response_cbs1.content)\n",
    "\n",
    "url_cbs2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=cbs-news&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_cbs2 = requests.get(url_cbs2)\n",
    "\n",
    "#print(response_cbs2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDtcr4HpLPgv"
   },
   "outputs": [],
   "source": [
    "url_hill1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=the-hill&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_hill1 = requests.get(url_hill1)\n",
    "\n",
    "#print(response_hill1.content)\n",
    "\n",
    "url_hill2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=virus&'\n",
    "       'sources=the-hill&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_hill2 = requests.get(url_hill2)\n",
    "\n",
    "#print(response_hill2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_lcHrwmLoGE"
   },
   "outputs": [],
   "source": [
    "url_reuters1 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=primary&'\n",
    "       'sources=reuters&'\n",
    "        'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-02-24&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_reuters1 = requests.get(url_reuters1)\n",
    "\n",
    "#print(response_reuters1.content)\n",
    "\n",
    "url_reuters2 = ('http://newsapi.org/v2/everything?'\n",
    "       'q=trump&'\n",
    "       'sources=reuters&'\n",
    "       'pageSize=100&'\n",
    "       'sortBy=popularity&'\n",
    "       'from=2020-03-15&'\n",
    "       'to=2020-03-24&'\n",
    "       'apiKey=dfb5e6075cc043b687b45876d6be0561')\n",
    "\n",
    "response_reuters2 = requests.get(url_reuters2)\n",
    "\n",
    "#print(response_reuters2.content)\n",
    "# response_reuters2.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7T04boIMGx_"
   },
   "source": [
    "# Decoding and Converting to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOxXM5MheLUD"
   },
   "source": [
    "Using the decode function was necessary to translate the list objects from News API so they could be converted to a json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "gd5YejjpvSXR",
    "outputId": "95a63522-0b24-4e91-d96b-680c5bccc0f7"
   },
   "outputs": [],
   "source": [
    "# response_fox1\n",
    "# response_fox2\n",
    "# response_bart1\n",
    "# response_bart2\n",
    "# response_nreview1\n",
    "# response_nreview2\n",
    "# response_nreview3\n",
    "\n",
    "print('Conservative sources, 1 partisan right, 2 skew right')\n",
    "response_fox1_d = response_fox1.content.decode(\"utf-8\")\n",
    "print(response_fox1_d)\n",
    "response_fox2_d = response_fox2.content.decode(\"utf-8\")\n",
    "print(response_fox2_d)\n",
    "\n",
    "response_bart1_d = response_bart1.content.decode(\"utf-8\")\n",
    "#print(response_bart1_d)\n",
    "response_bart2_d = response_bart2.content.decode(\"utf-8\")\n",
    "#print(response_bart2_d)\n",
    "\n",
    "response_nreview1_d = response_nreview1.content.decode(\"utf-8\")\n",
    "#print(response_nreview1_d)\n",
    "response_nreview2_d = response_nreview2.content.decode(\"utf-8\")\n",
    "#print(response_nreview2_d)\n",
    "response_nreview3_d = response_nreview3.content.decode(\"utf-8\")\n",
    "#print(response_nreview3_d)\n",
    "\n",
    "\n",
    "# response_vice1\n",
    "# response_vice2\n",
    "# response_msnbc1\n",
    "# response_msnbc2\n",
    "# response_msnbc3\n",
    "# response_buzz1\n",
    "# response_buzz2\n",
    "# response_buzz3\n",
    "\n",
    "print('Liberal sources, 1 partisan left, 2 skew left')\n",
    "response_vice1_d = response_vice1.content.decode(\"utf-8\")\n",
    "#print(response_vice1_d)\n",
    "response_vice2_d = response_vice2.content.decode(\"utf-8\")\n",
    "#print(response_vice2_d)\n",
    "\n",
    "response_msnbc1_d = response_msnbc1.content.decode(\"utf-8\")\n",
    "#print(response_msnbc1_d)\n",
    "response_msnbc2_d = response_msnbc2.content.decode(\"utf-8\")\n",
    "#print(response_msnbc2_d)\n",
    "response_msnbc3_d = response_msnbc3.content.decode(\"utf-8\")\n",
    "#print(response_msnbc3_d)\n",
    "\n",
    "response_buzz1_d = response_buzz1.content.decode(\"utf-8\")\n",
    "#print(response_buzz1_d)\n",
    "response_buzz2_d = response_buzz2.content.decode(\"utf-8\")\n",
    "#print(response_buzz2_d)\n",
    "response_buzz3_d = response_buzz3.content.decode(\"utf-8\")\n",
    "#print(response_buzz3_d)\n",
    "\n",
    "\n",
    "\n",
    "# response_hill1\n",
    "# response_hill2\n",
    "# response_reuters1\n",
    "# response_reuters2\n",
    "# response_cbs1\n",
    "# response_cbs2\n",
    "\n",
    "print('Neutral sources')\n",
    "response_hill1_d = response_hill1.content.decode(\"utf-8\")\n",
    "#print(response_hill1_d)\n",
    "response_hill2_d = response_hill2.content.decode(\"utf-8\")\n",
    "#print(response_hill2_d)\n",
    "\n",
    "response_reuters1_d = response_reuters1.content.decode(\"utf-8\")\n",
    "#print(response_reuters1_d)\n",
    "response_reuters2_d = response_reuters2.content.decode(\"utf-8\")\n",
    "#print(response_reuters2_d)\n",
    "\n",
    "response_cbs1_d = response_cbs1.content.decode(\"utf-8\")\n",
    "#print(response_cbs1_d)\n",
    "response_cbs2_d = response_cbs2.content.decode(\"utf-8\")\n",
    "#print(response_cbs2_d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(type(response_cbs2))\n",
    "type(response_cbs2_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTqEDn8XqMQs"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# response_1x = json.loads(response_1)\n",
    "# print(type(response_1x))\n",
    "# # print(response_1x)\n",
    "# response_1x['articles']\n",
    "\n",
    "\n",
    "\n",
    "#conservative\n",
    "response_fox1_j = json.loads(response_fox1_d)\n",
    "# response_fox1_j['articles']\n",
    "# response_fox1_j\n",
    "response_fox2_j = json.loads(response_fox2_d)\n",
    "\n",
    "\n",
    "response_bart1_j = json.loads(response_bart1_d)\n",
    "response_bart2_j = json.loads(response_bart2_d)\n",
    "\n",
    "response_nreview1_j = json.loads(response_nreview1_d)\n",
    "response_nreview2_j = json.loads(response_nreview2_d)\n",
    "response_nreview3_j = json.loads(response_nreview3_d)\n",
    "\n",
    "#liberal\n",
    "response_vice1_j = json.loads(response_vice1_d)\n",
    "response_vice2_j = json.loads(response_vice2_d)\n",
    "\n",
    "response_msnbc1_j = json.loads(response_msnbc1_d)\n",
    "response_msnbc2_j = json.loads(response_msnbc2_d)\n",
    "response_msnbc3_j = json.loads(response_msnbc3_d)\n",
    "\n",
    "response_buzz1_j = json.loads(response_buzz1_d)\n",
    "response_buzz2_j = json.loads(response_buzz2_d)\n",
    "response_buzz3_j = json.loads(response_buzz3_d)\n",
    "\n",
    "\n",
    "#neutral\n",
    "response_hill1_j = json.loads(response_hill1_d)\n",
    "response_hill2_j = json.loads(response_hill2_d)\n",
    "\n",
    "response_reuters1_j = json.loads(response_reuters1_d)\n",
    "response_reuters2_j = json.loads(response_reuters2_d)\n",
    "\n",
    "response_cbs1_j = json.loads(response_cbs1_d)\n",
    "response_cbs2_j = json.loads(response_cbs2_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjT74B06hv_K"
   },
   "source": [
    "# Converting JSON to pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ox0m72hmeeTn"
   },
   "source": [
    "We then used pandas to transform the each JSON object into a dataframe that could be easily read and wrangled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_CbPYqQqMcE"
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(response_1x['articles'])\n",
    "# df\n",
    "\n",
    "#conservative df's\n",
    "df_fox1 = pd.DataFrame(response_fox1_j['articles'])\n",
    "df_fox1\n",
    "df_fox2 = pd.DataFrame(response_fox2_j['articles'])\n",
    "df_fox2\n",
    "\n",
    "\n",
    "df_bart1 = pd.DataFrame(response_bart1_j['articles'])\n",
    "df_bart1\n",
    "df_bart2 = pd.DataFrame(response_bart2_j['articles'])\n",
    "df_bart2\n",
    " \n",
    "\n",
    "df_nreview1 = pd.DataFrame(response_nreview1_j['articles'])\n",
    "df_nreview1\n",
    "df_nreview2 = pd.DataFrame(response_nreview2_j['articles'])\n",
    "df_nreview2\n",
    "df_nreview3 = pd.DataFrame(response_nreview3_j['articles'])\n",
    "df_nreview3\n",
    "\n",
    "\n",
    "# #liberal\n",
    "\n",
    "df_vice1 = pd.DataFrame(response_vice1_j['articles'])\n",
    "df_vice1\n",
    "df_vice2 = pd.DataFrame(response_vice2_j['articles'])\n",
    "df_vice2\n",
    "\n",
    "df_msnbc1 = pd.DataFrame(response_msnbc1_j['articles'])\n",
    "df_msnbc1\n",
    "df_msnbc2 = pd.DataFrame(response_msnbc2_j['articles'])\n",
    "df_msnbc2\n",
    "df_msnbc3 = pd.DataFrame(response_msnbc3_j['articles'])\n",
    "df_msnbc3\n",
    "\n",
    "df_buzz1 = pd.DataFrame(response_buzz1_j['articles'])\n",
    "df_buzz1\n",
    "df_buzz2 = pd.DataFrame(response_buzz2_j['articles'])\n",
    "df_buzz2\n",
    "df_buzz3 = pd.DataFrame(response_buzz3_j['articles'])\n",
    "df_buzz3\n",
    "\n",
    "\n",
    "# #neutral\n",
    "df_hill1 = pd.DataFrame(response_hill1_j['articles'])\n",
    "df_hill1\n",
    "df_hill2 = pd.DataFrame(response_hill2_j['articles'])\n",
    "df_hill2\n",
    "\n",
    "df_reuters1 = pd.DataFrame(response_reuters1_j['articles'])\n",
    "df_reuters1\n",
    "df_reuters2 = pd.DataFrame(response_reuters2_j['articles'])\n",
    "df_reuters2\n",
    "\n",
    "df_cbs1 = pd.DataFrame(response_cbs1_j['articles'])\n",
    "df_cbs1\n",
    "df_cbs2 = pd.DataFrame(response_cbs1_j['articles'])\n",
    "df_cbs2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47F6gNL1j3Pk"
   },
   "source": [
    "# Merging Dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXynSQdXe0gC"
   },
   "source": [
    "After converting each JSON object into it's own dataframe, the pandas concat function was used to attach all of the rows of each of these dataframes together, creating one large dataframe of all of the scraped articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zu_vrHCFkfSX"
   },
   "outputs": [],
   "source": [
    "df_allsources = pd.concat([df_fox1, df_fox2, df_bart1, df_bart2, df_nreview1, df_nreview2, df_nreview3,\n",
    "                           df_msnbc1, df_msnbc2, df_msnbc3, df_buzz1, df_buzz2, df_buzz3, df_vice1, df_vice2,\n",
    "                           df_hill1, df_hill2, df_reuters1, df_reuters2, df_cbs1, df_cbs2])\n",
    "df_allsources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuJA91HYl8zT"
   },
   "outputs": [],
   "source": [
    "df_allsources.to_csv('newsapi_scrape1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sEt8SbNaaj_"
   },
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PaXPnO0aakA"
   },
   "source": [
    "#### We first had a conversation about which part of the API's we were going to be using. There were news articles that didn't have content, and if it did have content, it wasn't fully there. So going forward with cleaning we decided that we should gather all that we could as far as content wise, and we could decide what to do with it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OE8lGfyXaakB",
    "outputId": "ead9ea47-84a7-4b8b-b7ca-85d00d32e2e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 453 news articles that do not have content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "MarchNews = pd.read_csv('newsapi_scrape1.csv')\n",
    "#print(MarchNews)\n",
    "\n",
    "Nan = MarchNews['content'].isnull().sum()\n",
    "print(f'There are {Nan} news articles that do not have content')\n",
    "\n",
    "\n",
    "#Replacing Null values with 'None'\n",
    "MarchNews['content'].fillna(\"None\", inplace = True)\n",
    "MarchNews['title'].fillna('None', inplace = True)\n",
    "MarchNews['description'].fillna('None', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbOwDRKsaakF"
   },
   "source": [
    "#### The code underneath is finding all of the distinct words in the content, description, and title columns. Also using the re.findall function we were also able to remove the punctuation from the columns as well. After combing through the data we realized that the last two words were for the number of characters after whatever we had, so we scraped the last two entries in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfZpT6lraakG"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "Content = []\n",
    "Description = []\n",
    "Title = []\n",
    "\n",
    "for i in range(len(MarchNews['content'])):\n",
    "    Content.append(re.findall(r'\\w+', MarchNews['content'][i])[:-3])\n",
    "    Description.append(re.findall(r'\\w+', MarchNews['description'][i]))\n",
    "    Title.append(re.findall(r'\\w+', MarchNews['title'][i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dvl5q-P6aakK"
   },
   "source": [
    "#### The codeblock below is taking out any stopwords, and removing any numbers or unknown symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmwQUPGqaakK"
   },
   "outputs": [],
   "source": [
    "# Getting rid of Stopwords\n",
    "\n",
    "for i in range(len(Content)):\n",
    "    # Taking out the Stopwords\n",
    "    Content[i] = [words.lower() for words in Content[i] if words.lower() not in stopwords]\n",
    "    Title[i] = [words.lower() for words in Title[i] if words.lower() not in stopwords]\n",
    "    Description[i] = [words.lower() for words in Description[i] if words.lower() not in stopwords]\n",
    "    \n",
    "    # Taking out the non-string values\n",
    "    Content[i] = [words for words in Content[i] if words.isalpha() == True]\n",
    "    Title[i] = [words for words in Title[i] if words.isalpha() == True]\n",
    "    Description[i] = [words for words in Description[i] if words.isalpha() == True]\n",
    "    \n",
    "#print(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgpOdbTQaakN",
    "outputId": "b4d3f609-9413-470e-d99f-b28aaa498fb3"
   },
   "outputs": [],
   "source": [
    "MarchNews.insert(8,'TitleCleaned', Title)\n",
    "MarchNews.insert(9,'DescriptionCleaned', Description)\n",
    "MarchNews.insert(10,'ContentCleaned', Content)\n",
    "#print(MarchNews[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwWQNk6maakP",
    "outputId": "c8174f9b-eaf0-407b-e849-2943907a362b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1784 entries, 0 to 1783\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   source              1784 non-null   object\n",
      " 1   author              1745 non-null   object\n",
      " 2   title               1784 non-null   object\n",
      " 3   description         1784 non-null   object\n",
      " 4   url                 1784 non-null   object\n",
      " 5   urlToImage          1751 non-null   object\n",
      " 6   publishedAt         1784 non-null   object\n",
      " 7   content             1784 non-null   object\n",
      " 8   TitleCleaned        1784 non-null   object\n",
      " 9   DescriptionCleaned  1784 non-null   object\n",
      " 10  ContentCleaned      1784 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 153.4+ KB\n"
     ]
    }
   ],
   "source": [
    "MarchNews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCL6NCrbaakT"
   },
   "source": [
    "# Get Unique Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAJw3DmQaakT"
   },
   "source": [
    "#### In order to use a machine learning algrorithm, we first needed to convert our data into a useable format since we can't train an agorithm on words alone. We originally tried to match and count words in an article to a set of predefined, politically loaded words and terms. These polarizing terms included \"death tax\", \"estate tax\", \"pro life\", \"pro choice\", \"gun safety\", \"gun control\", and more. However, we found that matching these terms to news from the last month is not very effective since most of the coverage has been on COVID-19 and the democratic primary. \n",
    "\n",
    "#### We plan on reading through some of the articles and creating a new matrix of words and terms to match to/count in earch article. Before that is done, we first need to prep the data. To do this, we first extracted a list of unique words from each news article. Once we have a new matrix of political words and terms, we can iterate through each list of unique words to see if any of our words of interest appear in that article. If a word appears, we can then iterate through the words in that article to get a word count. The final result of this process would be a matrix where words/phrases make up the columns, and each row represents an article, and the cells would be populated with numbers representing the count of that columns word or phrase in the article. This matrix could then be fed into an algorithm such as SVM, averaged Perceptron, or Logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yT2jC112aakU"
   },
   "outputs": [],
   "source": [
    "# get unique words for each column\n",
    "uniqueWords = []\n",
    "\n",
    "for i in range(len(MarchNews['ContentCleaned'])):\n",
    "    # create empty lsit each iteration\n",
    "    lst = []\n",
    "    # get all word in title, content, and description\n",
    "    [lst.append(words) for words in MarchNews['TitleCleaned'][i]]\n",
    "    [lst.append(words) for words in MarchNews['ContentCleaned'][i]]\n",
    "    [lst.append(words) for words in MarchNews['DescriptionCleaned'][i]]\n",
    "    #transform list into set of unique words\n",
    "    unique = set(lst)\n",
    "    #assign unique word set to each row or whole df\n",
    "    uniqueWords.append(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5sO79puaakW",
    "outputId": "c8d211f3-6079-4733-d27d-e58956075ad7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>content</th>\n",
       "      <th>TitleCleaned</th>\n",
       "      <th>DescriptionCleaned</th>\n",
       "      <th>ContentCleaned</th>\n",
       "      <th>uniqueWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': 'fox-news', 'name': 'Fox News'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sanders supporters react to DNC reportedly att...</td>\n",
       "      <td>Fox News contributor Lawrence Jones speaks to ...</td>\n",
       "      <td>http://video.foxnews.com/v/6136724620001/</td>\n",
       "      <td>https://cf-images.us-east-1.prod.boltdns.net/v...</td>\n",
       "      <td>2020-02-28T03:43:40Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[sanders, supporters, react, dnc, reportedly, ...</td>\n",
       "      <td>[fox, news, contributor, lawrence, jones, spea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{fox, supporters, attempting, sanders, nominat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   source author  \\\n",
       "1  {'id': 'fox-news', 'name': 'Fox News'}    NaN   \n",
       "\n",
       "                                               title  \\\n",
       "1  Sanders supporters react to DNC reportedly att...   \n",
       "\n",
       "                                         description  \\\n",
       "1  Fox News contributor Lawrence Jones speaks to ...   \n",
       "\n",
       "                                         url  \\\n",
       "1  http://video.foxnews.com/v/6136724620001/   \n",
       "\n",
       "                                          urlToImage           publishedAt  \\\n",
       "1  https://cf-images.us-east-1.prod.boltdns.net/v...  2020-02-28T03:43:40Z   \n",
       "\n",
       "  content                                       TitleCleaned  \\\n",
       "1    None  [sanders, supporters, react, dnc, reportedly, ...   \n",
       "\n",
       "                                  DescriptionCleaned ContentCleaned  \\\n",
       "1  [fox, news, contributor, lawrence, jones, spea...             []   \n",
       "\n",
       "                                         uniqueWords  \n",
       "1  {fox, supporters, attempting, sanders, nominat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new row in big DF with unique words\n",
    "MarchNews.insert(11,'uniqueWords', uniqueWords)\n",
    "MarchNews[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_sB3sZoaakZ",
    "outputId": "2aa2aed7-0570-4d6f-ed0d-7b3cd47e176e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'house', 'fox', 'campaign', 'tammy', 'white', 'chief', 'reaction', 'priebus', 'die', 'south', 'contributor', 'biden', 'news', 'former', 'reince', 'primary', 'staff', 'carolina', 'bruce'}\n"
     ]
    }
   ],
   "source": [
    "print(MarchNews['uniqueWords'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gV8AIg-daakc"
   },
   "source": [
    "#### We are also considering comparing the unique words between news sources as a way of training an algorithm. The code below extracts all of the unique words used by each news source.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9sbvR2Raakd"
   },
   "outputs": [],
   "source": [
    "# group df by source\n",
    "# index numbers--> 0 = Breitbart, 1 = Buzzfeed, 2 = CBS, 3 = Fox, 4 = MSNBC, \n",
    "#                  5 = National-Review, 6 = Reuters, 7 = The Hill, 8 = Vice News \n",
    "uniqueWords_allSources = MarchNews.groupby('source')['uniqueWords'].apply(list)\n",
    "\n",
    "# right\n",
    "breitbart_words = uniqueWords_allSources.iloc[[0]]\n",
    "fox_words = uniqueWords_allSources.iloc[[3]]\n",
    "natReview_words = uniqueWords_allSources.iloc[[5]]\n",
    "\n",
    "# middle\n",
    "cbs_words = uniqueWords_allSources.iloc[[2]]\n",
    "reuters_words = uniqueWords_allSources.iloc[[6]]\n",
    "hill_words = uniqueWords_allSources.iloc[[7]]\n",
    "\n",
    "# left\n",
    "buzzfeed_words = uniqueWords_allSources.iloc[[1]]\n",
    "msnbc_words = uniqueWords_allSources.iloc[[4]]\n",
    "vice_words = uniqueWords_allSources.iloc[[8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kD_MUYBaakh",
    "outputId": "8eb4edd0-00fe-4ba7-b548-f9c127bc6b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2782\n",
      "1319\n",
      "1787\n"
     ]
    }
   ],
   "source": [
    "# function that creates set of unique words for each source\n",
    "\n",
    "def unique_by_source(series):\n",
    "    lst =[]\n",
    "    for i in series[0]:\n",
    "        lst.extend(i)\n",
    "    new_set = set(lst)\n",
    "    return new_set\n",
    "\n",
    "# right\n",
    "unique_breitbart_words = unique_by_source(breitbart_words)\n",
    "unique_fox_words = unique_by_source(fox_words)\n",
    "unique_natReview_words = unique_by_source(natReview_words)\n",
    "\n",
    "# middle\n",
    "unique_cbs_words = unique_by_source(cbs_words)\n",
    "unique_reuters_words = unique_by_source(reuters_words)\n",
    "unique_hill_words = unique_by_source(hill_words)\n",
    "\n",
    "# left\n",
    "unique_buzzfeed_words = unique_by_source(buzzfeed_words) \n",
    "unique_msnbc_words = unique_by_source(msnbc_words)\n",
    "unique_vice_words = unique_by_source(vice_words)\n",
    "\n",
    "\n",
    "Left = set(list(unique_buzzfeed_words) + list(unique_msnbc_words) + list(unique_vice_words))\n",
    "Middle = set(list(unique_cbs_words) + list(unique_reuters_words) + list(unique_hill_words))\n",
    "Right = set(list(unique_breitbart_words) + list(unique_fox_words) + list(unique_natReview_words))\n",
    "\n",
    "\n",
    "UniquelyLeft = [w for w in Left if w not in Middle and w not in Right]\n",
    "\n",
    "UniquelyMiddle = [w for w in Middle if w not in Left and w not in Right]\n",
    "\n",
    "UniquelyRight = [w for w in Right if w not in Left and w not in Middle]\n",
    "\n",
    "print(len(UniquelyLeft))\n",
    "print(len(UniquelyRight))\n",
    "print(len(UniquelyMiddle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strangled',\n",
       " 'plummeting',\n",
       " 'respirator',\n",
       " 'foster',\n",
       " 'presi',\n",
       " 'disappr',\n",
       " 'ro',\n",
       " 'siding',\n",
       " 'emirates',\n",
       " 'fbc',\n",
       " 'gala',\n",
       " 'grounded',\n",
       " 'weaponize',\n",
       " 'fervent',\n",
       " 'sandersbloomberg',\n",
       " 'bloombergbloomberg',\n",
       " 'sidewalk',\n",
       " 'forecasts',\n",
       " 'burnish',\n",
       " 'awarding',\n",
       " 'appoint',\n",
       " 'approves',\n",
       " 'donovan',\n",
       " 'sisolak',\n",
       " 'disrespect',\n",
       " 'booties',\n",
       " 'mnuchin',\n",
       " 'urban',\n",
       " 'command',\n",
       " 'campaigningmore',\n",
       " 'coronavirusmet',\n",
       " 'advertisements',\n",
       " 'tenants',\n",
       " 'ackman',\n",
       " 'philips',\n",
       " 'deepens',\n",
       " 'branch',\n",
       " 'greased',\n",
       " 'barron',\n",
       " 'runnin',\n",
       " 'narula',\n",
       " 'norwegian',\n",
       " 'taxpayer',\n",
       " 'gun',\n",
       " 'sustain',\n",
       " 'rumors',\n",
       " 'diego',\n",
       " 'subsequent',\n",
       " 'greek',\n",
       " 'speculated',\n",
       " 'pools',\n",
       " 'hate',\n",
       " 'racing',\n",
       " 'poses',\n",
       " 'sens',\n",
       " 'coronavirussanders',\n",
       " 'ensuring',\n",
       " 'sweeping',\n",
       " 'muskelon',\n",
       " 'restrict',\n",
       " 'takeaways',\n",
       " 'nwc',\n",
       " 'paula',\n",
       " 'onslaught',\n",
       " 'enacted',\n",
       " 'sotomayor',\n",
       " 'ssrs',\n",
       " 'migrant',\n",
       " 'preventions',\n",
       " 'offense',\n",
       " 'armed',\n",
       " 'pleas',\n",
       " 'sentenced',\n",
       " 'reverberating',\n",
       " 'yangandrew',\n",
       " 'jamie',\n",
       " 'turf',\n",
       " 'rebuff',\n",
       " 'warrenbloomberg',\n",
       " 'freshman',\n",
       " 'restricts',\n",
       " 'lockdownthis',\n",
       " 'healthcoronavirus',\n",
       " 'cris',\n",
       " 'coronavirusde',\n",
       " 'diane',\n",
       " 'withholding',\n",
       " 'bemoans',\n",
       " 'sanjay',\n",
       " 'crimes',\n",
       " 'personnel',\n",
       " 'older',\n",
       " 'deploy',\n",
       " 'accusations',\n",
       " 'economists',\n",
       " 'poorly',\n",
       " 'lesson',\n",
       " 'appropriations',\n",
       " 'flown',\n",
       " 'independence',\n",
       " 'recognize',\n",
       " 'bears',\n",
       " 'gr',\n",
       " 'tide',\n",
       " 'bassett',\n",
       " 'ernstjoni',\n",
       " 'maker',\n",
       " 'gig',\n",
       " 'adjust',\n",
       " 'congratulatory',\n",
       " 'opts',\n",
       " 'municipalities',\n",
       " 'electronic',\n",
       " 'mexicans',\n",
       " 'asserts',\n",
       " 'sessionsjefferson',\n",
       " 'selfies',\n",
       " 'trumpthe',\n",
       " 'consumption',\n",
       " 'proposalsmore',\n",
       " 'bp',\n",
       " 'saudi',\n",
       " 'brokerage',\n",
       " 'obrador',\n",
       " 'zhong',\n",
       " 'barrel',\n",
       " 'subpoena',\n",
       " 'gosarpaul',\n",
       " 'coronavirushillicon',\n",
       " 'warrenelizabeth',\n",
       " 'maher',\n",
       " 'greater',\n",
       " 'eroded',\n",
       " 'comment',\n",
       " 'dock',\n",
       " 'bucking',\n",
       " 'scrutiny',\n",
       " 'banks',\n",
       " 'title',\n",
       " 'rican',\n",
       " 'pulls',\n",
       " 'bleak',\n",
       " 'rancor',\n",
       " 'provisions',\n",
       " 'economies',\n",
       " 'rampage',\n",
       " 'breach',\n",
       " 'containing',\n",
       " 'confined',\n",
       " 'rac',\n",
       " 'scotthouse',\n",
       " 'valuable',\n",
       " 'wrongly',\n",
       " 'ba',\n",
       " 'schw',\n",
       " 'coors',\n",
       " 'overhaul',\n",
       " 'gripping',\n",
       " 'maherbuttigieg',\n",
       " 'abo',\n",
       " 'rourke',\n",
       " 'crossings',\n",
       " 'shunned',\n",
       " 'khannarohit',\n",
       " 'screenings',\n",
       " 'idling',\n",
       " 'trusted',\n",
       " 'alterna',\n",
       " 'broadcasting',\n",
       " 'preps',\n",
       " 'airways',\n",
       " 'execs',\n",
       " 'bloombergbiden',\n",
       " 'wounds',\n",
       " 'adopting',\n",
       " 'febreze',\n",
       " 'downgrade',\n",
       " 'facts',\n",
       " 'giant',\n",
       " 'responseobama',\n",
       " 'marty',\n",
       " 'paint',\n",
       " 'briefed',\n",
       " 'delaysthe',\n",
       " 'carsonsunday',\n",
       " 'docking',\n",
       " 'hatching',\n",
       " 'exercises',\n",
       " 'lay',\n",
       " 'tibetan',\n",
       " 'intensify',\n",
       " 'employers',\n",
       " 'interfax',\n",
       " 'thailand',\n",
       " 'gregg',\n",
       " 'garamendi',\n",
       " 'layoffs',\n",
       " 'omalley',\n",
       " 'helene',\n",
       " 'operate',\n",
       " 'dodges',\n",
       " 'threw',\n",
       " 'garamendipeace',\n",
       " 'opting',\n",
       " 'evaluate',\n",
       " 'nearing',\n",
       " 'checks',\n",
       " 'bowser',\n",
       " 'frequently',\n",
       " 'debatesanders',\n",
       " 'pennsylvania',\n",
       " 'dumped',\n",
       " 'fukushima',\n",
       " 'plunged',\n",
       " 'racethe',\n",
       " 'moorestephen',\n",
       " 'bidensanders',\n",
       " 'pompeo',\n",
       " 'sandersrepublicans',\n",
       " 'speed',\n",
       " 'acostajames',\n",
       " 'choking',\n",
       " 'rulingthe',\n",
       " 'discriminating',\n",
       " 'disposal',\n",
       " 'dermatology',\n",
       " 'lego',\n",
       " 'ivanka',\n",
       " 'surged',\n",
       " 'preparations',\n",
       " 'patchwork',\n",
       " 'pasteur',\n",
       " 'defines',\n",
       " 'rely',\n",
       " 'bloom',\n",
       " 'onuma',\n",
       " 'rallythe',\n",
       " 'primarieswarren',\n",
       " 'petroleum',\n",
       " 'peers',\n",
       " 'comprehensive',\n",
       " 'deborah',\n",
       " 'linked',\n",
       " 'onstage',\n",
       " 'reiterating',\n",
       " 'nc',\n",
       " 'obtain',\n",
       " 'martha',\n",
       " 'heart',\n",
       " 'goodwin',\n",
       " 'tensionsmore',\n",
       " 'delaying',\n",
       " 'output',\n",
       " 'griffith',\n",
       " 'administered',\n",
       " 'confront',\n",
       " 'wis',\n",
       " 'raffensperger',\n",
       " 'sharpest',\n",
       " 'presentations',\n",
       " 'carolinabiden',\n",
       " 'lib',\n",
       " 'unthinkable',\n",
       " 'blocs',\n",
       " 'exemptions',\n",
       " 'levers',\n",
       " 'georgias',\n",
       " 'retreatsmore',\n",
       " 'movements',\n",
       " 'amzn',\n",
       " 'jan',\n",
       " 'statistically',\n",
       " 'doris',\n",
       " 'unsettling',\n",
       " 'debatefive',\n",
       " 'beer',\n",
       " 'lobbied',\n",
       " 'lined',\n",
       " 'arabia',\n",
       " 'invites',\n",
       " 'ge',\n",
       " 'incident',\n",
       " 'scaled',\n",
       " 'currency',\n",
       " 'demanding',\n",
       " 'intensification',\n",
       " 'ibrahim',\n",
       " 'poured',\n",
       " 'secondary',\n",
       " 'collinssunday',\n",
       " 'explainer',\n",
       " 'attended',\n",
       " 'contributed',\n",
       " 'souls',\n",
       " 'eroding',\n",
       " 'cottonhillicon',\n",
       " 'recount',\n",
       " 'buffets',\n",
       " 'defeating',\n",
       " 'coronavirusmeghan',\n",
       " 'irish',\n",
       " 'verbal',\n",
       " 'strategic',\n",
       " 'lawmake',\n",
       " 'opponentwatch',\n",
       " 'cyberattack',\n",
       " 'tournaments',\n",
       " 'reciting',\n",
       " 'coronavirushouse',\n",
       " 'dorian',\n",
       " 'communityappeals',\n",
       " 'portfolios',\n",
       " 'barrack',\n",
       " 'easter',\n",
       " 'ford',\n",
       " 'brokered',\n",
       " 'chicken',\n",
       " 'fx',\n",
       " 'commonweal',\n",
       " 'faults',\n",
       " 'sessionstrump',\n",
       " 'sandersadvisor',\n",
       " 'holmes',\n",
       " 'cha',\n",
       " 'mortgages',\n",
       " 'khannatrump',\n",
       " 'manuel',\n",
       " 'bloombergwinners',\n",
       " 'mammals',\n",
       " 'factbox',\n",
       " 'parscalemore',\n",
       " 'eclipse',\n",
       " 'affiliate',\n",
       " 'steamrolls',\n",
       " 'alleging',\n",
       " 'aired',\n",
       " 'amit',\n",
       " 'duncan',\n",
       " 'ceremony',\n",
       " 'millennials',\n",
       " 'delayspence',\n",
       " 'outwarren',\n",
       " 'politicsmellman',\n",
       " 'divisive',\n",
       " 'anchorage',\n",
       " 'trumpadvisor',\n",
       " 'warrenmore',\n",
       " 'laying',\n",
       " 'discovered',\n",
       " 'bolstering',\n",
       " 'rage',\n",
       " 'au',\n",
       " 'ser',\n",
       " 'melbourne',\n",
       " 'coronavirusmore',\n",
       " 'mat',\n",
       " 'commercial',\n",
       " 'accessed',\n",
       " 'zeroes',\n",
       " 'destroying',\n",
       " 'encourage',\n",
       " 'electoral',\n",
       " 'broad',\n",
       " 'links',\n",
       " 'malfunctions',\n",
       " 'perezclintons',\n",
       " 'hardline',\n",
       " 'radar',\n",
       " 'dropoff',\n",
       " 'othertexas',\n",
       " 'bidenpress',\n",
       " 'doom',\n",
       " 'carsonbenjamin',\n",
       " 'kept',\n",
       " 'noble',\n",
       " 'cronies',\n",
       " 'debatethe',\n",
       " 'bidentrump',\n",
       " 'warsaw',\n",
       " 'lunar',\n",
       " 'forms',\n",
       " 'yuji',\n",
       " 'backstop',\n",
       " 'raceex',\n",
       " 'interactive',\n",
       " 'jackie',\n",
       " 'permitted',\n",
       " 'behalf',\n",
       " 'ii',\n",
       " 'personne',\n",
       " 'draw',\n",
       " 'collinsdouglas',\n",
       " 'trumpivana',\n",
       " 'surgeelon',\n",
       " 'trumpthis',\n",
       " 'greenwood',\n",
       " 'grateful',\n",
       " 'scuffle',\n",
       " 'rand',\n",
       " 'tuesdayjudd',\n",
       " 'warrior',\n",
       " 'fray',\n",
       " 'publicly',\n",
       " 'pelosinancy',\n",
       " 'eateries',\n",
       " 'mobilized',\n",
       " 'botches',\n",
       " 'asserting',\n",
       " 'motor',\n",
       " 'python',\n",
       " 'stretched',\n",
       " 'activities',\n",
       " 'cornynsurveillance',\n",
       " 'multibillion',\n",
       " 'expense',\n",
       " 'garcetti',\n",
       " 'celebrations',\n",
       " 'statesmore',\n",
       " 'f',\n",
       " 'doane',\n",
       " 'fatherly',\n",
       " 'iryna',\n",
       " 'harden',\n",
       " 'conduits',\n",
       " 'kiev',\n",
       " 'stoke',\n",
       " 'appoints',\n",
       " 'controlgop',\n",
       " 'bigotry',\n",
       " 'modifies',\n",
       " 'derelict',\n",
       " 'drugmaker',\n",
       " 'gs',\n",
       " 'sons',\n",
       " 'knees',\n",
       " 'decisive',\n",
       " 'coronavirusvoters',\n",
       " 'sandersthe',\n",
       " 'courts',\n",
       " 'tonights',\n",
       " 'glance',\n",
       " 'pouring',\n",
       " 'helicopters',\n",
       " 'policymakers',\n",
       " 'pizzeria',\n",
       " 'dillon',\n",
       " 'apply',\n",
       " 'hillicon',\n",
       " 'liberals',\n",
       " 'shortened',\n",
       " 'stimulate',\n",
       " 'wasteful',\n",
       " 'advances',\n",
       " 'echoes',\n",
       " 'flop',\n",
       " 'parscalebradley',\n",
       " 'accelerating',\n",
       " 'sandersbernie',\n",
       " 'gaining',\n",
       " 'yields',\n",
       " 'cybersecurity',\n",
       " 'brasilia',\n",
       " 'nih',\n",
       " 'seth',\n",
       " 'ukraine',\n",
       " 'freaked',\n",
       " 'offing',\n",
       " 'densely',\n",
       " 'gain',\n",
       " 'spencer',\n",
       " 'fcc',\n",
       " 'carolinasanders',\n",
       " 'concernsturns',\n",
       " 'harley',\n",
       " 'outweighing',\n",
       " 'cinched',\n",
       " 'donates',\n",
       " 'cede',\n",
       " 'vetting',\n",
       " 'pencemichael',\n",
       " 'blo',\n",
       " 'tracts',\n",
       " 'reddit',\n",
       " 'californias',\n",
       " 'ally',\n",
       " 'sxsw',\n",
       " 'brings',\n",
       " 'withdrew',\n",
       " 'corporations',\n",
       " 'ticketing',\n",
       " 'partnering',\n",
       " 'stewart',\n",
       " 'tackling',\n",
       " 'copyright',\n",
       " 'code',\n",
       " 'preferred',\n",
       " 'municipal',\n",
       " 'refusal',\n",
       " 'maherwilliam',\n",
       " 'bully',\n",
       " 'remained',\n",
       " 'crude',\n",
       " 'reduced',\n",
       " 'spotmeet',\n",
       " 'insufficient',\n",
       " 'trumpde',\n",
       " 'eric',\n",
       " 'basque',\n",
       " 'appointed',\n",
       " 'marcos',\n",
       " 'evaluated',\n",
       " 'dueling',\n",
       " 'buttigiegpeter',\n",
       " 'lauded',\n",
       " 'protester',\n",
       " 'outstanding',\n",
       " 'downheritage',\n",
       " 'opdivo',\n",
       " 'nationals',\n",
       " 'bureaucracy',\n",
       " 'preferential',\n",
       " 'edged',\n",
       " 'investor',\n",
       " 'breadbasket',\n",
       " 'presses',\n",
       " 'drillers',\n",
       " 'glimpse',\n",
       " 'kicks',\n",
       " 'shown',\n",
       " 'locks',\n",
       " 'plurality',\n",
       " 'draws',\n",
       " 'carolinademocrats',\n",
       " 'casessanders',\n",
       " 'ankara',\n",
       " 'ol',\n",
       " 'outplacement',\n",
       " 'rent',\n",
       " 'novembe',\n",
       " 'soci',\n",
       " 'mcconnelladdison',\n",
       " 'clintontrump',\n",
       " 'bristol',\n",
       " 'overtaken',\n",
       " 'appe',\n",
       " 'delaysmore',\n",
       " 'corps',\n",
       " 'curtailed',\n",
       " 'molson',\n",
       " 'procedures',\n",
       " 'youn',\n",
       " 'olive',\n",
       " 'allowance',\n",
       " 'liked',\n",
       " 'kelly',\n",
       " 'opens',\n",
       " 'ingrahamlaura',\n",
       " 'machines',\n",
       " 'impatience',\n",
       " 'ted',\n",
       " 'spur',\n",
       " 'compliance',\n",
       " 'fading',\n",
       " 'jeopardized',\n",
       " 'ingrahamfox',\n",
       " 'suckerpunch',\n",
       " 'manipulated',\n",
       " 'scaling',\n",
       " 'overshadows',\n",
       " 'toughest',\n",
       " 'cortezthe',\n",
       " 'episode',\n",
       " 'tibet',\n",
       " 'racemore',\n",
       " 'brakes',\n",
       " 'argentina',\n",
       " 'peking',\n",
       " 'negotiators',\n",
       " 'procedural',\n",
       " 'liver',\n",
       " 'mcconnellthis',\n",
       " 'kilograms',\n",
       " 'requested',\n",
       " 'tempers',\n",
       " 'panicked',\n",
       " 'skyrocket',\n",
       " 'sub',\n",
       " 'operations',\n",
       " 'garamendijohn',\n",
       " 'easley',\n",
       " 'aviation',\n",
       " 'judie',\n",
       " 'freshly',\n",
       " 'bloombergmichael',\n",
       " 'dissipates',\n",
       " 'fax',\n",
       " 'tariff',\n",
       " 'closest',\n",
       " 'boxerformer',\n",
       " 'fresno',\n",
       " 'waves',\n",
       " 'communiti',\n",
       " 'makers',\n",
       " 'obrien',\n",
       " 'mr',\n",
       " 'entry',\n",
       " 'bombarded',\n",
       " 'loans',\n",
       " 'largely',\n",
       " 'norway',\n",
       " 'regions',\n",
       " 'subsidiary',\n",
       " 'bidenbiden',\n",
       " 'drumbeat',\n",
       " 'wti',\n",
       " 'intensive',\n",
       " 'centrist',\n",
       " 'initiatives',\n",
       " 'statesbiden',\n",
       " 'virginias',\n",
       " 'attracting',\n",
       " 'cigs',\n",
       " 'attends',\n",
       " 'balance',\n",
       " 'steepest',\n",
       " 'communicating',\n",
       " 'pummeled',\n",
       " 'sir',\n",
       " 'institut',\n",
       " 'johnston',\n",
       " 'aipac',\n",
       " 'floridas',\n",
       " 'futaba',\n",
       " 'yervoy',\n",
       " 'securities',\n",
       " 'closings',\n",
       " 'practices',\n",
       " 'buildings',\n",
       " 'asimendinger',\n",
       " 'discretionary',\n",
       " 'string',\n",
       " 'claimslindsey',\n",
       " 'develop',\n",
       " 'requesting',\n",
       " 'interference',\n",
       " 'reassures',\n",
       " 'raring',\n",
       " 'fundraiser',\n",
       " 'electionthe',\n",
       " 'crosshairs',\n",
       " 'sighed',\n",
       " 'productsmore',\n",
       " 'ind',\n",
       " 'implementing',\n",
       " 'bureau',\n",
       " 'tucked',\n",
       " 'consolidate',\n",
       " 'pledging',\n",
       " 'turbulent',\n",
       " 'coffee',\n",
       " 'dips',\n",
       " 'downgrades',\n",
       " 'guatemala',\n",
       " 'guys',\n",
       " 'ernstovernight',\n",
       " 'suppression',\n",
       " 'lifeline',\n",
       " 'primariesvulnerable',\n",
       " 'taxi',\n",
       " 'cooperation',\n",
       " 'klas',\n",
       " 'philanthropies',\n",
       " 'aiming',\n",
       " 'fisheries',\n",
       " 'deadlier',\n",
       " 'amending',\n",
       " 'bidenovernight',\n",
       " 'inoculating',\n",
       " 'consultant',\n",
       " 'cruz',\n",
       " 'nathan',\n",
       " 'evidencelabors',\n",
       " 'conducte',\n",
       " 'placing',\n",
       " 'ages',\n",
       " 'brent',\n",
       " 'drilling',\n",
       " 'liquidity',\n",
       " 'planemaker',\n",
       " 'asses',\n",
       " 'filing',\n",
       " 'revived',\n",
       " 'trumpratcliffe',\n",
       " 'surveys',\n",
       " 'strokes',\n",
       " 'bidenmore',\n",
       " 'inventory',\n",
       " 'aol',\n",
       " 'nervous',\n",
       " 'deported',\n",
       " 'sheets',\n",
       " 'amendments',\n",
       " 'relay',\n",
       " 'disembarking',\n",
       " 'restaurant',\n",
       " 'directive',\n",
       " 'volunteers',\n",
       " 'borrows',\n",
       " 'wonthe',\n",
       " 'granted',\n",
       " 'racetexas',\n",
       " 'bidenformer',\n",
       " 'shanghai',\n",
       " 'payments',\n",
       " 'regulators',\n",
       " 'li',\n",
       " 'intensified',\n",
       " 'midwest',\n",
       " 'tel',\n",
       " 'wwii',\n",
       " 'chores',\n",
       " 'overwhelmingly',\n",
       " 'minimize',\n",
       " 'jitters',\n",
       " 'atrocious',\n",
       " 'sandersfive',\n",
       " 'baker',\n",
       " 'kalin',\n",
       " 'qan',\n",
       " 'rodham',\n",
       " 'chip',\n",
       " 'carolinacongress',\n",
       " 'http',\n",
       " 'diagnose',\n",
       " 'introduces',\n",
       " 'acknowledging',\n",
       " 'intervene',\n",
       " 'capping',\n",
       " 'debatemore',\n",
       " 'fonda',\n",
       " 'su',\n",
       " 'workday',\n",
       " 'incidents',\n",
       " 'paulson',\n",
       " 'uncharted',\n",
       " 'tweet',\n",
       " 'athletic',\n",
       " 'spraying',\n",
       " 'vassilis',\n",
       " 'ark',\n",
       " 'spr',\n",
       " 'pollmore',\n",
       " 'replace',\n",
       " 'doug',\n",
       " 'sullivan',\n",
       " 'uncontested',\n",
       " 'batters',\n",
       " 'ul',\n",
       " 'broaden',\n",
       " 'parent',\n",
       " 'reassure',\n",
       " 'selcuk',\n",
       " 'xenophobia',\n",
       " 'burbank',\n",
       " 'revive',\n",
       " 'triumph',\n",
       " 'contestsmore',\n",
       " 'commentswhat',\n",
       " 'brush',\n",
       " 'cyclemores',\n",
       " 'nominationon',\n",
       " 'sleepless',\n",
       " 'blistering',\n",
       " 'slashing',\n",
       " 'dodge',\n",
       " 'generacion',\n",
       " 'refineries',\n",
       " 'intention',\n",
       " 'democratsklobuchar',\n",
       " 'treasury',\n",
       " 'evans',\n",
       " 'attached',\n",
       " 'extends',\n",
       " 'clintonhillary',\n",
       " 'nagging',\n",
       " 'roles',\n",
       " 'shorten',\n",
       " 'olympia',\n",
       " 'cures',\n",
       " 'counts',\n",
       " 'saharan',\n",
       " 'toughening',\n",
       " 'bolton',\n",
       " 'steelmakers',\n",
       " 'tied',\n",
       " 'foresees',\n",
       " 'ascendent',\n",
       " 'commitment',\n",
       " 'mourns',\n",
       " 'install',\n",
       " 'liner',\n",
       " 'balloting',\n",
       " 'darkest',\n",
       " 'resp',\n",
       " 'merchandise',\n",
       " 'deepened',\n",
       " 'cortezalexandria',\n",
       " 'kindergartens',\n",
       " 'foregoes',\n",
       " 'suspected',\n",
       " 'prompts',\n",
       " 'futures',\n",
       " 'primarieson',\n",
       " 'khanna',\n",
       " 'landlords',\n",
       " 'tune',\n",
       " 'crossing',\n",
       " 'sanderspress',\n",
       " 'currencies',\n",
       " 'puerto',\n",
       " 'isabella',\n",
       " 'arab',\n",
       " 'coordinate',\n",
       " 'requests',\n",
       " 'destroyed',\n",
       " 'hanging',\n",
       " 'confuses',\n",
       " 'fallen',\n",
       " 'dooley',\n",
       " 'plummeted',\n",
       " 'slammed',\n",
       " 'juggle',\n",
       " 'mobs',\n",
       " 'digital',\n",
       " 'palmer',\n",
       " 'nerves',\n",
       " 'tenn',\n",
       " 'disrupts',\n",
       " 'marzio',\n",
       " 'coveralls',\n",
       " 'jalisco',\n",
       " 'winsvan',\n",
       " 'coro',\n",
       " 'globallybiden',\n",
       " 'winbloomberg',\n",
       " 'thei',\n",
       " 'resurgence',\n",
       " 'nueva',\n",
       " 'neal',\n",
       " 'footage',\n",
       " 'duri',\n",
       " 'brick',\n",
       " 'pinch',\n",
       " 'cyberspace',\n",
       " 'directing',\n",
       " 'comfortable',\n",
       " 'unseat',\n",
       " 'targets',\n",
       " 'unnamed',\n",
       " 'sao',\n",
       " 'jeopardize',\n",
       " 'cottonthomas',\n",
       " 'contained',\n",
       " 'tier',\n",
       " 'credibility',\n",
       " 'dividend',\n",
       " 'buybacks',\n",
       " 'refrain',\n",
       " 'freed',\n",
       " 'towering',\n",
       " 'buffering',\n",
       " 'cruiseliner',\n",
       " 'tailspin',\n",
       " 'decisively',\n",
       " 'sympathetic',\n",
       " 'corp',\n",
       " 'harassment',\n",
       " 'postpress',\n",
       " 'tobacco',\n",
       " 'sanctions',\n",
       " 'aided',\n",
       " 'envoy',\n",
       " 'famously',\n",
       " 'suar',\n",
       " 'crater',\n",
       " 'exchanged',\n",
       " 'blm',\n",
       " 'psomas',\n",
       " 'flowing',\n",
       " 'eventual',\n",
       " 'fortnight',\n",
       " 'joebiden',\n",
       " 'imf',\n",
       " 'bias',\n",
       " 'ellis',\n",
       " 'cements',\n",
       " 'mobilize',\n",
       " 'historyfox',\n",
       " 'furlough',\n",
       " 'hud',\n",
       " 'brewery',\n",
       " 'presents',\n",
       " 'storms',\n",
       " 'brussels',\n",
       " 'bloc',\n",
       " 'investigating',\n",
       " 'unemployment',\n",
       " 'obsolete',\n",
       " 'talent',\n",
       " 'abolished',\n",
       " 'cbsn',\n",
       " 'exhibiting',\n",
       " 'compmore',\n",
       " 'eavesdropping',\n",
       " 'ax',\n",
       " 'references',\n",
       " 'malley',\n",
       " 'fuels',\n",
       " 'quarters',\n",
       " 'sandweg',\n",
       " 'videomore',\n",
       " 'rider',\n",
       " 'jerome',\n",
       " 'payouts',\n",
       " 'clerks',\n",
       " 'insist',\n",
       " 'handshakes',\n",
       " 'collins',\n",
       " 'statistic',\n",
       " 'muskhillicon',\n",
       " 'litmus',\n",
       " 'spared',\n",
       " 'trounced',\n",
       " 'viewership',\n",
       " 'revenues',\n",
       " 'msnbcs',\n",
       " 'teaches',\n",
       " 'buoyed',\n",
       " 'contemplating',\n",
       " 'evacuating',\n",
       " 'mitch',\n",
       " 'warrenwinners',\n",
       " 'quashed',\n",
       " 'resume',\n",
       " 'credit',\n",
       " 'legislator',\n",
       " 'breed',\n",
       " 'misperception',\n",
       " 'authored',\n",
       " 'reeve',\n",
       " 'sector',\n",
       " 'agriculture',\n",
       " 'seriou',\n",
       " 'appropriate',\n",
       " 'correction',\n",
       " 'troop',\n",
       " 'tracy',\n",
       " 'boar',\n",
       " 'hank',\n",
       " 'tuesdaydelegate',\n",
       " 'squibb',\n",
       " 'glided',\n",
       " 'deceptive',\n",
       " 'tuesdaymore',\n",
       " 'lineup',\n",
       " 'vector',\n",
       " 'unaccompanied',\n",
       " 'auctions',\n",
       " 'increases',\n",
       " 'crunch',\n",
       " 'estimating',\n",
       " 'caucusespoll',\n",
       " 'coronavirusselection',\n",
       " 'sachs',\n",
       " 'advance',\n",
       " 'rebound',\n",
       " 'concernsjuan',\n",
       " 'offshore',\n",
       " 'ireland',\n",
       " 'previews',\n",
       " 'lifespan',\n",
       " 'bet',\n",
       " 'reactions',\n",
       " 'gq',\n",
       " 'solomon',\n",
       " 'gordon',\n",
       " 'calms',\n",
       " 'exp',\n",
       " 'monthly',\n",
       " 'vapes',\n",
       " 'tuesdaythe',\n",
       " 'organizing',\n",
       " 'muslim',\n",
       " 'prompted',\n",
       " 'suite',\n",
       " 'monique',\n",
       " 'bolder',\n",
       " 'shoved',\n",
       " 'freshener',\n",
       " 'square',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniquelyMiddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sanders' in UniquelyMiddle"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DetectingMediaBias.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
